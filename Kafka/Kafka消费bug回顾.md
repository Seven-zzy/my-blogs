### 问题回放 <br>
由于微服务架构要求各微服务数据库隔离，某微服务A需要读取基础资源微服务B的数据，项目中通过kafka来中转。微服务B数据变更全部写入kafka，微服务A循环向kafka取数据。
<br>
某天线上突然出现微服务A与B的数据出现不一致，B生产的数据若干小时后A服务的页面上还无法查看到。将A服务日志取回，发现是A服务一直在重复消费一条消息，
kafka server默认的消费成功回执超时时间为30s，A作为消费者，遇到了一条超大消息，30s没有消费完成，没有发送ack给kafka server，导致server认为消费失败，
陷入了消费失败的死循环。

### 原因分析
为了保证消息确实是成功消费的，A服务消费消息没有异步处理，而是等全部消息真正处理完成后才发送ack给kafka server。然而，这一次遇到了超大消息，导致消费超时，
进入了重复消费同一条消息的死循环，导致后续消息无法正常消费，产生了与生产者的数据不一致问题。
这里有2个问题点。
#### 1.没有考虑到kafka server的消费超时时间。默认时间是30s，该时间可修改，封装后的kafka server支持restful请求的参数中指定超时时间。发生该问题后，
将消费的超时时间改为了300s。
#### 2.A服务消费消息全部为单线程处理，若遇到超大消息，单线程处理速度有限，就算延长了超时时间，也无法保证每次消息一定能在300s内消费完成。所以在消费消息
处做了个改动，当一次传来的消息长度超过一定限制，则另起线程消费，然后直接向kafka server发送消费成功的ack。

### 总结
开源工具好用是建立在正确使用的基础上，而正确使用的基础是对工具的了解。<br>
永远都不要忽视超时、资源不足等异常情况。
